{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a href=\"https://cognitiveclass.ai\"><img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/Logos/organization_logo/organization_logo.png\" width = 400> </a>\n",
    "\n",
    "<h1 align=center><font size = 5>Pre-Trained Models</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab, you will learn how to leverage pre-trained models to build image classifiers instead of building a model from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 3> \n",
    "    \n",
    "1. <a href=\"#item31\">Import Libraries and Packages</a>\n",
    "2. <a href=\"#item32\">Download Data</a>  \n",
    "3. <a href=\"#item33\">Define Global Constants</a>  \n",
    "4. <a href=\"#item34\">Construct ImageDataGenerator Instances</a>  \n",
    "5. <a href=\"#item35\">Compile and Fit Model</a>\n",
    "\n",
    "</font>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item31'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Import Libraries and Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's start the lab by importing the libraries that we will be using in this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "First, we will import the ImageDataGenerator module since we will be leveraging it to train our model in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab, we will be using the Keras library to build an image classifier, so let's download the Keras library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, we will be leveraging the ResNet50 model to build our classifier, so let's download it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item32'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "For your convenience, I have placed the data on a server which you can retrieve easily using the **wget** command. So let's run the following line of code to get the data. Given the large size of the image dataset, it might take some time depending on your internet speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-08-22 21:11:46--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip\n",
      "Resolving s3-api.us-geo.objectstorage.softlayer.net... 67.228.254.196\n",
      "Connecting to s3-api.us-geo.objectstorage.softlayer.net|67.228.254.196|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 261482368 (249M) [application/zip]\n",
      "Saving to: 'concrete_data_week3.zip.1'\n",
      "\n",
      "concrete_data_week3 100%[===================>] 249.37M  6.77MB/s    in 29s     \n",
      "\n",
      "2020-08-22 21:12:16 (8.58 MB/s) - 'concrete_data_week3.zip.1' saved [261482368/261482368]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## get the data\n",
    "#!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now if you check the left directory pane, you should see the zipped file *concrete_data_week3.zip* appear. So, let's go ahead and unzip the file to access the images. Given the large number of images in the dataset, this might take a couple of minutes, so please be patient, and wait until the code finishes running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  concrete_data_week3.zip\n",
      "replace concrete_data_week3/valid/positive/16679_1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "#!unzip concrete_data_week3.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, you should see the folder *concrete_data_week3* appear in the left pane. If you open this folder by double-clicking on it, you will find that it contains two folders: *train* and *valid*. And if you explore these folders, you will find that each contains two subfolders: *positive* and *negative*. These are the same folders that we saw in the labs in the previous modules of this course, where *negative* is the negative class and it represents the concrete images with no cracks and *positive* is the positive class and it represents the concrete images with cracks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Important Note**: There are thousands and thousands of images in each folder, so please don't attempt to double click on the *negative* and *positive* folders. This may consume all of your memory and you may end up with a **50*** error. So please **DO NOT DO IT**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item33'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Define Global Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Here, we will define constants that we will be using throughout the rest of the lab. \n",
    "\n",
    "1. We are obviously dealing with two classes, so *num_classes* is 2. \n",
    "2. The ResNet50 model was built and trained using images of size (224 x 224). Therefore, we will have to resize our images from (227 x 227) to (224 x 224).\n",
    "3. We will training and validating the model using batches of 100 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "image_resize = 224\n",
    "\n",
    "batch_size_training = 100\n",
    "batch_size_validation = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item34'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Construct ImageDataGenerator Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In order to instantiate an ImageDataGenerator instance, we will set the **preprocessing_function** argument to *preprocess_input* which we imported from **keras.applications.resnet50** in order to preprocess our images the same way the images used to train ResNet50 model were processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will use the *flow_from_directory* method to get the training images as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/train',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Your Turn**: Use the *flow_from_directory* method to get the validation images and assign the result to **validation_generator**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## Type your answer here\n",
    "validation_generator = data_generator.flow_from_directory('concrete_data_week3/valid', target_size=(image_resize, image_resize),\n",
    "                                                           batch_size=batch_size_validation, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Double-click __here__ for the solution.\n",
    "<!-- The correct answer is:\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode='categorical')\n",
    "-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item35'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Build, Compile and Fit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this section, we will start building our model. We will use the Sequential model class from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will add the ResNet50 pre-trained model to out model. However, note that we don't want to include the top layer or the output layer of the pre-trained model. We actually want to define our own output layer and train it so that it is optimized for our image dataset. In order to leave out the output layer of the pre-trained model, we will use the argument *include_top* and set it to **False**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.add(ResNet50(\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    weights='imagenet',\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Then, we will define our output layer as a **Dense** layer, that consists of two nodes and uses the **Softmax** function as the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can access the model's layers using the *layers* attribute of our model object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.training.Model at 0x7feaed94bc90>,\n",
       " <keras.layers.core.Dense at 0x7fead6190f50>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can see that our model is composed of two sets of layers. The first set is the layers pertaining to ResNet50 and the second set is a single layer, which is our Dense layer that we defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can access the ResNet50 layers by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7feaf1bfa8d0>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7feaf1bfaa50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feaf1c01cd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feaf8318d90>,\n",
       " <keras.layers.core.Activation at 0x7feaf8324d10>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7feaf832dd50>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7feaf832a610>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feaf83d0b90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feaf8d1d590>,\n",
       " <keras.layers.core.Activation at 0x7feaf8cab390>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feaf8d1dad0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feaf8d86ed0>,\n",
       " <keras.layers.core.Activation at 0x7feaf8d9fb50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feaf9136b90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feaf91a9790>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feaf91a9bd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feaf92542d0>,\n",
       " <keras.layers.merge.Add at 0x7feaf92e6590>,\n",
       " <keras.layers.core.Activation at 0x7feaf92968d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feaf932e790>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feaf93889d0>,\n",
       " <keras.layers.core.Activation at 0x7feaf93e10d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feaf941cc50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feaf946fb90>,\n",
       " <keras.layers.core.Activation at 0x7feaf946fd90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feaf9507f10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feaf951acd0>,\n",
       " <keras.layers.merge.Add at 0x7feaf9591f10>,\n",
       " <keras.layers.core.Activation at 0x7feaf95773d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feaf95eee90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feaf9962710>,\n",
       " <keras.layers.core.Activation at 0x7feaf99d9d50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feaf9977c90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feaf9a4ac10>,\n",
       " <keras.layers.core.Activation at 0x7feaf9a69c90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feaf9ae58d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feaf9b38fd0>,\n",
       " <keras.layers.merge.Add at 0x7feaf9b38b90>,\n",
       " <keras.layers.core.Activation at 0x7feaf9b4f2d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feaf9bd19d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feaf9c36550>,\n",
       " <keras.layers.core.Activation at 0x7feaf9c367d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feaf9cba8d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feaf9e28d10>,\n",
       " <keras.layers.core.Activation at 0x7feaf9ea2ed0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feaf9ebc2d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feafa319890>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feafa319ed0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feafa3baa90>,\n",
       " <keras.layers.merge.Add at 0x7feafa41af10>,\n",
       " <keras.layers.core.Activation at 0x7feafa401f10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feafa49c5d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feafa507c90>,\n",
       " <keras.layers.core.Activation at 0x7feafa522f10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feafa5895d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feafa5f2ed0>,\n",
       " <keras.layers.core.Activation at 0x7feafa70ab50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feafa76ca10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feafa7e0f90>,\n",
       " <keras.layers.merge.Add at 0x7feafa85ce10>,\n",
       " <keras.layers.core.Activation at 0x7feafa7e0310>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feafa8768d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feafa8d0950>,\n",
       " <keras.layers.core.Activation at 0x7feafa8e7f90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feafa967f10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feafa9a2e50>,\n",
       " <keras.layers.core.Activation at 0x7feafa9a2c90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feafaa4fe90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feafaabbe90>,\n",
       " <keras.layers.merge.Add at 0x7feafaad5b10>,\n",
       " <keras.layers.core.Activation at 0x7feafac39c90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feafac39f50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feafacaab90>,\n",
       " <keras.layers.core.Activation at 0x7feaface2fd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feafad3e790>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feafad95e90>,\n",
       " <keras.layers.core.Activation at 0x7feafad959d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feafae2fd50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feafb6c3e10>,\n",
       " <keras.layers.merge.Add at 0x7feafb6c3c50>,\n",
       " <keras.layers.core.Activation at 0x7feafb6db1d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feafb759e10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feafb7c3950>,\n",
       " <keras.layers.core.Activation at 0x7feafb93eb10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feafb7dafd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feafb9b5ed0>,\n",
       " <keras.layers.core.Activation at 0x7feafba27f10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feafba4a450>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feafcc34dd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feafcc1eb90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feafccc6c50>,\n",
       " <keras.layers.merge.Add at 0x7feafcd5b890>,\n",
       " <keras.layers.core.Activation at 0x7feafcd09c10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feafcda3790>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feafce12e50>,\n",
       " <keras.layers.core.Activation at 0x7feafce2fb10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feafce92f50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feafcefcb10>,\n",
       " <keras.layers.core.Activation at 0x7feafcf78f50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feafcefc490>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feafcfebe90>,\n",
       " <keras.layers.merge.Add at 0x7feafd05ffd0>,\n",
       " <keras.layers.core.Activation at 0x7feafcfebed0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feafd080ad0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feafd0d3d50>,\n",
       " <keras.layers.core.Activation at 0x7feafd208e10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feafd271e90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feafd27cfd0>,\n",
       " <keras.layers.core.Activation at 0x7feafd2f8e90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feafd354c10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feafd3c5ad0>,\n",
       " <keras.layers.merge.Add at 0x7feafd43ffd0>,\n",
       " <keras.layers.core.Activation at 0x7feafd3c5450>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feafd4593d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feafd4b4e10>,\n",
       " <keras.layers.core.Activation at 0x7feafd70e050>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feafd749950>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feafd79dfd0>,\n",
       " <keras.layers.core.Activation at 0x7feafd79dc10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feafd836e50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feadfd0ff50>,\n",
       " <keras.layers.merge.Add at 0x7feadfd40e50>,\n",
       " <keras.layers.core.Activation at 0x7feadfd9cf50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feadfd9cbd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feadff0f890>,\n",
       " <keras.layers.core.Activation at 0x7feadff87d10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feadff9f450>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feadfffa9d0>,\n",
       " <keras.layers.core.Activation at 0x7feae0061fd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feae00de8d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feae012ffd0>,\n",
       " <keras.layers.merge.Add at 0x7feae012fb90>,\n",
       " <keras.layers.core.Activation at 0x7feae01462d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feae01c9f10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feae0370550>,\n",
       " <keras.layers.core.Activation at 0x7feae03707d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feae03e88d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feae0458d10>,\n",
       " <keras.layers.core.Activation at 0x7feae04d2ed0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feae04ef2d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feae0541750>,\n",
       " <keras.layers.merge.Add at 0x7feae055ffd0>,\n",
       " <keras.layers.core.Activation at 0x7feae05dd5d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feae05dda10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feae0649350>,\n",
       " <keras.layers.core.Activation at 0x7feae06a5dd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feae06c95d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feae0832ed0>,\n",
       " <keras.layers.core.Activation at 0x7feae084bb50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feae08afa10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feae4b21850>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feae4b21fd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feae4bc93d0>,\n",
       " <keras.layers.merge.Add at 0x7feae4c43dd0>,\n",
       " <keras.layers.core.Activation at 0x7feae4c10d90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feae4c73890>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feae4d00850>,\n",
       " <keras.layers.core.Activation at 0x7feae4d5b210>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feae4d59f10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feae4deae50>,\n",
       " <keras.layers.core.Activation at 0x7feae4deac90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feae4f7ee90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feae4fe8e90>,\n",
       " <keras.layers.merge.Add at 0x7feae5002b10>,\n",
       " <keras.layers.core.Activation at 0x7feae4fe8990>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feae5067c90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feae50da810>,\n",
       " <keras.layers.core.Activation at 0x7feae5212dd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feae526e790>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feae52c5e90>,\n",
       " <keras.layers.core.Activation at 0x7feae52c59d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7feae535dd50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7feae53b4e10>,\n",
       " <keras.layers.merge.Add at 0x7feae53b4c50>,\n",
       " <keras.layers.core.Activation at 0x7feae53c91d0>,\n",
       " <keras.layers.pooling.GlobalAveragePooling2D at 0x7feae5067f50>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since the ResNet50 model has already been trained, then we want to tell our model not to bother with training the ResNet part, but to train only our dense output layer. To do that, we run the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now using the *summary* attribute of the model, we can see how many parameters we will need to optimize in order to train the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next we compile our model using the **adam** optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Before we are able to start the training process, with an ImageDataGenerator, we will need to define how many steps compose an epoch. Typically, that is the number of images divided by the batch size. Therefore, we define our steps per epoch as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "steps_per_epoch_training = len(train_generator)\n",
    "steps_per_epoch_validation = len(validation_generator)\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, we are ready to start training our model. Unlike a conventional deep learning training were data is not streamed from a directory, with an ImageDataGenerator where data is augmented in batches, we use the **fit_generator** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_training,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=steps_per_epoch_validation,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now that the model is trained, you are ready to start using it to classify images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since training can take a long time when building deep learning models, it is always a good idea to save your model once the training is complete if you believe you will be using the model again later. You will be using this model in the next module, so go ahead and save your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.save('classifier_resnet_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, you should see the model file *classifier_resnet_model.h5* apprear in the left directory pane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Thank you for completing this lab!\n",
    "\n",
    "This notebook was created by Alex Aklson. I hope you found this lab interesting and educational."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "This notebook is part of a course on **Coursera** called *AI Capstone Project with Deep Learning*. If you accessed this notebook outside the course, you can take this course online by clicking [here](https://cocl.us/DL0321EN_Coursera_Week3_LAB1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "Copyright &copy; 2020 [IBM Developer Skills Network](https://cognitiveclass.ai/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
